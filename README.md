# Real-time Speaker Diarization System

Há»‡ thá»‘ng nháº­n diá»‡n ngÆ°á»i nÃ³i vÃ  chuyá»ƒn Ä‘á»•i giá»ng nÃ³i thÃ nh vÄƒn báº£n thá»i gian thá»±c vá»›i 3 models khÃ¡c nhau.

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
realtime/
â”œâ”€â”€ README.md                          # TÃ i liá»‡u nÃ y
â”œâ”€â”€ requirements.txt                   # Dependencies chung
â”œâ”€â”€ requirements_sen_voice.txt         # Dependencies cho SenseVoice
â”‚
â”œâ”€â”€ realtime_diarization_improved.py   # Model 1: Whisper + SpeechBrain
â”œâ”€â”€ sen_voice.py                      # Model 2: SenseVoice
â”œâ”€â”€ senvoi_spebrai_fixed.py           # Model 3: SenseVoice + SpeechBrain
â”‚
â”œâ”€â”€ dataset/                          # Dataset JVS Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
â”‚   â””â”€â”€ jvs_ver1/
â”œâ”€â”€ pretrained_models/                # Models Ä‘Ã£ táº£i vá»
â”œâ”€â”€ evaluation/                       # Scripts Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh
â”‚   â”œâ”€â”€ eval_asr.py                  # ÄÃ¡nh giÃ¡ ASR (Speech Recognition)
â”‚   â”œâ”€â”€ eval_diarization.py          # ÄÃ¡nh giÃ¡ Diarization
â”‚   â”œâ”€â”€ compared.py                  # So sÃ¡nh káº¿t quáº£ ASR
â”‚   â”œâ”€â”€ compare_diarization.py       # So sÃ¡nh káº¿t quáº£ Diarization
â”‚   â”œâ”€â”€ eval_results/                # Káº¿t quáº£ Ä‘Ã¡nh giÃ¡
â”‚   â””â”€â”€ *.bat                        # Batch files Ä‘á»ƒ cháº¡y dá»… dÃ ng
â”‚
â”œâ”€â”€ tmp_model/                        # Models táº¡m thá»i
â”œâ”€â”€ venv/                            # Virtual environment
â””â”€â”€ *.json                           # Output files tá»« cÃ¡c láº§n cháº¡y
```

## ğŸš€ CÃ i Ä‘áº·t vÃ  Khá»Ÿi táº¡o

### 1. Táº¡o Virtual Environment

```bash
cd realtime
python -m venv venv

# KÃ­ch hoáº¡t virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### 2. CÃ i Ä‘áº·t Dependencies

```bash
# CÃ i Ä‘áº·t packages cÆ¡ báº£n
pip install -r requirements.txt

# CÃ i Ä‘áº·t packages cho SenseVoice
pip install -r requirements_sen_voice.txt

# Packages bá»• sung cho evaluation
pip install pandas matplotlib seaborn scikit-learn
```

## ğŸ¯ CÃ¡c Models Available

### 1. **Whisper + SpeechBrain** (`realtime_diarization_improved.py`)

- **ASR**: Whisper Small
- **Speaker Diarization**: SpeechBrain ECAPA-TDNN
- **Æ¯u Ä‘iá»ƒm**: Äá»™ chÃ­nh xÃ¡c ASR cao, diarization tá»‘t
- **NhÆ°á»£c Ä‘iá»ƒm**: Tá»‘c Ä‘á»™ cháº­m nháº¥t (RTF ~2.7)

### 2. **SenseVoice** (`sen_voice.py`)

- **ASR**: SenseVoice Small (FunAudioLLM)
- **Speaker Diarization**: KhÃ´ng cÃ³
- **Æ¯u Ä‘iá»ƒm**: Tá»‘c Ä‘á»™ nhanh, Ä‘á»™ chÃ­nh xÃ¡c ASR cao
- **NhÆ°á»£c Ä‘iá»ƒm**: KhÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c ngÆ°á»i nÃ³i

### 3. **SenseVoice + SpeechBrain** (`senvoi_spebrai_fixed.py`)

- **ASR**: SenseVoice Small
- **Speaker Diarization**: SpeechBrain ECAPA-TDNN
- **Æ¯u Ä‘iá»ƒm**: **Tá»‘t nháº¥t** - Tá»‘c Ä‘á»™ nhanh nháº¥t (RTF ~0.35), Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t
- **NhÆ°á»£c Ä‘iá»ƒm**: CÃ i Ä‘áº·t phá»©c táº¡p hÆ¡n

## ğŸ¤ Cháº¡y Real-time Recognition

### Cháº¡y tá»«ng model riÃªng láº»:

```bash
# Model 1: Whisper + SpeechBrain
python realtime_diarization_improved.py

# Model 2: SenseVoice only
python sen_voice.py

# Model 3: SenseVoice + SpeechBrain (recommended)
python senvoi_spebrai_fixed.py
```

### Output:

- Console: Hiá»ƒn thá»‹ real-time transcript
- JSON file: LÆ°u chi tiáº¿t vá»›i timestamp (format: `[model]_output_YYYYMMDD_HHMMSS.json`)

## ğŸ“Š ÄÃ¡nh giÃ¡ vÃ  So sÃ¡nh Models

### 1. ÄÃ¡nh giÃ¡ ASR (Speech Recognition)

```bash
cd evaluation

# Cháº¡y Ä‘Ã¡nh giÃ¡ ASR cho cáº£ 3 models
eval_asr.bat

# Hoáº·c Python trá»±c tiáº¿p
python eval_asr.py --max_files 100  # Test nhanh vá»›i 100 files
python eval_asr.py                  # Full dataset (~14,000+ files)
```

### 2. ÄÃ¡nh giÃ¡ Diarization

```bash
cd evaluation

# Cháº¡y Ä‘Ã¡nh giÃ¡ diarization
eval_diarization.bat

# Hoáº·c Python trá»±c tiáº¿p
python eval_diarization.py --max_files 100  # Test nhanh
python eval_diarization.py                  # Full dataset
```

### 3. So sÃ¡nh káº¿t quáº£

```bash
# So sÃ¡nh káº¿t quáº£ ASR
python compared.py

# So sÃ¡nh káº¿t quáº£ Diarization
python compare_diarization.py
```

## ğŸ“ˆ Káº¿t quáº£ ÄÃ¡nh giÃ¡

### ASR Performance (trÃªn JVS dataset):

| Model                        | WER (%)   | CER (%)  | RTF       | Real-time |
| ---------------------------- | --------- | -------- | --------- | --------- |
| **SenseVoice + SpeechBrain** | **11.70** | **8.32** | **0.355** | âœ…        |
| SenseVoice                   | 13.89     | 10.08    | 0.805     | âœ…        |
| Whisper + SpeechBrain        | 16.12     | 12.58    | 2.749     | âŒ        |

### Diarization Performance:

| Model                        | DER (%)  | F1 (%)    | RTF       | Real-time |
| ---------------------------- | -------- | --------- | --------- | --------- |
| **SenseVoice + SpeechBrain** | **5.33** | **91.84** | **0.049** | âœ…        |
| Whisper + SpeechBrain        | 10.36    | 93.54     | 0.168     | âœ…        |
| SenseVoice                   | 87.27    | 76.58     | 0.084     | âœ…        |

### ğŸ† **Káº¿t luáº­n**:

**SenseVoice + SpeechBrain** lÃ  model tá»‘t nháº¥t vá»›i:

- WER tháº¥p nháº¥t (11.70%)
- DER tháº¥p nháº¥t (5.33%)
- RTF nhanh nháº¥t (0.355 cho ASR, 0.049 cho diarization)
- Kháº£ nÄƒng real-time tá»‘t nháº¥t

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p:

1. **ImportError vá»›i SpeechBrain/FunASR**:

```bash
pip install --upgrade speechbrain funasr
pip install soundfile librosa torch torchaudio
```

2. **CUDA not available**:

- Models sáº½ tá»± Ä‘á»™ng chuyá»ƒn vá» CPU
- Tá»‘c Ä‘á»™ cháº­m hÆ¡n nhÆ°ng váº«n hoáº¡t Ä‘á»™ng

3. **Microphone khÃ´ng hoáº¡t Ä‘á»™ng**:

```bash
pip install sounddevice
# Kiá»ƒm tra device available
python -c "import sounddevice as sd; print(sd.query_devices())"
```

4. **Memory errors**:

- Giáº£m `CHUNK_SEC` trong config
- Sá»­ dá»¥ng CPU thay vÃ¬ CUDA

### Cáº¥u hÃ¬nh tÃ¹y chá»‰nh:

Sá»­a cÃ¡c thÃ´ng sá»‘ trong file Python:

```python
SAMPLE_RATE = 16000    # Sample rate
CHUNK_SEC = 3.0        # Äá»™ dÃ i má»—i chunk (giÃ¢y)
OVERLAP_SEC = 0.3      # Overlap giá»¯a cÃ¡c chunk
DEVICE = "cpu"         # hoáº·c "cuda"
```

## ğŸ“ Output Format

### JSON Output Structure:

```json
{
  "start_time": "2025-11-28T10:30:00.000000",
  "model": "SenseVoice + SpeechBrain",
  "device": "cpu",
  "sample_rate": 16000,
  "segments": [
    {
      "start_time": 0.0,
      "end_time": 3.2,
      "duration": 3.2,
      "text": "Xin chÃ o, tÃ´i lÃ  ngÆ°á»i nÃ³i sá»‘ má»™t",
      "speaker": "speaker_1",
      "confidence": 0.95
    },
    {
      "start_time": 3.5,
      "end_time": 6.8,
      "duration": 3.3,
      "text": "VÃ  tÃ´i lÃ  ngÆ°á»i nÃ³i sá»‘ hai",
      "speaker": "speaker_2",
      "confidence": 0.92
    }
  ]
}
```

## ğŸ›  Development

### ThÃªm model má»›i:

1. Táº¡o file Python má»›i theo template
2. Implement interface tÆ°Æ¡ng tá»± cÃ¡c model cÃ³ sáºµn
3. ThÃªm vÃ o `MODELS` dict trong evaluation scripts
4. Cháº¡y evaluation Ä‘á»ƒ so sÃ¡nh

### Customize evaluation:

- Sá»­a `eval_asr.py` vÃ  `eval_diarization.py`
- ThÃªm metrics má»›i vÃ o comparison scripts
- TÃ¹y chá»‰nh visualizations trong plot functions

## ğŸ“š References

- **Whisper**: OpenAI Whisper ASR model
- **SenseVoice**: FunAudioLLM SenseVoice Small
- **SpeechBrain**: ECAPA-TDNN speaker recognition
- **JVS Dataset**: Japanese Versatile Speech corpus
- **Evaluation Metrics**: WER, CER, DER, RTF, F1-score

---